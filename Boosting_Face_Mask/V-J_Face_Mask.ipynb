{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "structured-punch",
   "metadata": {},
   "source": [
    "# Important notes:\n",
    "    if you wanna run this code make sure that minNeighbors and scaleFactor fit your conditions (light, brightness, camsize etc)\n",
    "    for example                                 minNeighbors, scaleFactor\n",
    "    masks = mask_cascade.detectMultiScale(gray,     1.34    ,     18     ) \n",
    "    if you wanna see an example video of runs (model 4-6) after i optimized those weights you can go to dir ./openMe/...\n",
    "    also added vid that shows the features chosen for model 4\n",
    "\n",
    "    need to change with these since too low vals gives you alot of false Positives\n",
    "    and too high give false Negatives\n",
    "\n",
    "    the color of your mask is not the same color as the background (black mask on dark background doesnt give bad results and not included in my test). \n",
    "    my test is 200 photos (100 pos, 100 neg) i took by myself using my webcan wearing blue standat mask at night (room's light).\n",
    "\n",
    "    for the 4th, 5th and 6th models there are videos that demonstrate real-time use at the folder OPEN_ME in this task folder.\n",
    "    its better then if you try to use urself since youll have to adjust  minNeighbors, scaleFactor to make model work well.\n",
    "\n",
    "    I ran this project on my Ubunto VM. therefor not every print is here, but i mentioned the results.\n",
    "    \n",
    "    There are no grapths of the learning curves since plt.plot_model function support only objects that support .fit command, so if we wanna draw we have to create the model of 1 stages from ubunto (~15 min) + create the model of 2 stages from ubunto (~35 min) + .... + create the model of 25 stages from ubunto (~240 min) this work is hard and consumes too much time, and without knowlege in scripts we have to type commands menually each time (traincastade -stages=1, traincastade -stages=2, ..., traincastade -stages=25)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "academic-match",
   "metadata": {},
   "source": [
    "handeling the data\n",
    "--------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "complete-optimum",
   "metadata": {},
   "source": [
    "    copy the basic imports from CNN solution to handle the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "turkish-expense",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import json\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "import tensorflow as tf\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import zipfile\n",
    "import random\n",
    "import shutil\n",
    "from shutil import copyfile\n",
    "from os import getcwd\n",
    "from os import listdir\n",
    "import cv2\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.utils import shuffle\n",
    "import imutils\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image  as mpimg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "emerging-hypothesis",
   "metadata": {},
   "outputs": [],
   "source": [
    "anno_dir ='F:\\\\MLBig\\\\Creating_VJ_Cascade\\\\Medical Mask\\\\annotations'\n",
    "images_dir = 'F:\\\\MLBig\\\\Creating_VJ_Cascade\\\\Medical Mask\\\\images'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pharmaceutical-reynolds",
   "metadata": {},
   "source": [
    "    code added to create info.dat / bg.txt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hindu-career",
   "metadata": {},
   "outputs": [],
   "source": [
    "images=[]\n",
    "labels=[]\n",
    "\n",
    "f=open('info.dat', 'w')\n",
    "fb = open('bg.txt', 'w')\n",
    "masked_img  = False\n",
    "for filename in os.listdir(images_dir):\n",
    "    num = filename.split('.')[ 0 ]\n",
    "    print(\"loading image: {}\".format(filename))\n",
    "    if int(num) > 1800:\n",
    "        class_name = None\n",
    "        anno = filename + \".json\"\n",
    "        with open(os.path.join(anno_dir, anno)) as json_file:\n",
    "            json_data = json.load(json_file)\n",
    "            no_anno = json_data[\"NumOfAnno\"]\n",
    "            k = 0\n",
    "            for i in range(0, no_anno):\n",
    "                class_nam = json_data['Annotations'][i]['classname']\n",
    "                if class_nam in ['face_with_mask',\"gas_mask\", \"face_shield\", \"mask_surgical\", \"mask_colorful\"]:\n",
    "                    class_name = 'face_with_mask'\n",
    "                    k = i\n",
    "                    masked_img = True\n",
    "                    break\n",
    "                elif class_nam in ['face_no_mask,\"hijab_niqab', 'face_other_covering', \"face_with_mask_incorrect\", \"scarf_bandana\", \"balaclava_ski_mask\", \"other\" ]:\n",
    "                    class_name = 'face_no_mask'\n",
    "                    k = i\n",
    "                    masked_img = False\n",
    "                    break\n",
    "                else:\n",
    "                    continue\n",
    "                    \n",
    "            box = json_data[ 'Annotations' ][k][ 'BoundingBox' ]\n",
    "            (x1, x2, y1, y2) = box\n",
    "            print('point:'+str(x1)+','+str(x2)+','+str(y1)+','+str(y2))\n",
    "            if masked_img:\n",
    "                f.write('Medical Mask\\\\images\\\\' + filename + ' 1 ' + str(x1) + ' ' + str(x2) + ' ' +  str(y1) + ' ' + str(y2) + ' \\n')\n",
    "            else:\n",
    "                fb.write('Medical Mask\\\\images\\\\' + filename + ' \\n')\n",
    "        if class_name is not None: # we ignore some faces here\n",
    "            image = cv2.imread(os.path.join(images_dir, filename))\n",
    "            img = image[x2:y2, x1:y1]\n",
    "            img = cv2.resize(img, (224, 224))\n",
    "            img = img[...,::-1].astype(np.float32)\n",
    "            img = preprocess_input(img)\n",
    "            images.append(img)\n",
    "            labels.append(class_name)  \n",
    "   \n",
    "f.close()\n",
    "fb.close()\n",
    "images = np.array(images, dtype=\"float32\")\n",
    "labels = np.array(labels)\n",
    "print(len(images))\n",
    "print(len(labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "generous-solomon",
   "metadata": {},
   "source": [
    "FIRST ATTEMT TO CREATE haar cascade classifier for faceMask detection\n",
    "----------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "handed-injection",
   "metadata": {},
   "source": [
    "    we create pos and neg dirs for the data convert it to gray and cut the faces with our labels (only for pos since anything is really negative)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "renewable-justice",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "from csv import reader\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def store_raw_images():\n",
    "    pic_num = 1\n",
    "    name = \"\"    \n",
    "    if not os.path.exists('pos'):\n",
    "        os.makedirs('pos')\n",
    "        \n",
    "    with open(\"info.dat\",'r') as read_obj:\n",
    "        # pass the file object to reader() to get the reader object\n",
    "        csv_reader = reader(read_obj)\n",
    "        # Iterate over each row in the csv using reader object\n",
    "        for i in csv_reader:\n",
    "            splitted = i[0].split(\" \")\n",
    "            srcPathName = splitted[0] + \" \" + splitted[1]\n",
    "            num_of_obj = splitted[2]\n",
    "            x1 = splitted[3]\n",
    "            x2 = splitted[4]  \n",
    "            y1 = splitted[5]\n",
    "            y2 = splitted[6]\n",
    "            for j in i[0].split(\".\"):\n",
    "                i[0] = i[0].strip()\n",
    "                j=j[0:3] # remove space\n",
    "                #.xxx extensions\n",
    "                if pic_num == 1: # cus i testet first\n",
    "                    pic_num += 1\n",
    "                    continue\n",
    "                if j not in ['jpg', 'png']:\n",
    "                    continue\n",
    "                try:\n",
    "                    print(i[0])\n",
    "                    if j == 'jpg':\n",
    "                        name = \"pos/\"+str(pic_num)+\".jpg\"\n",
    "                        os.rename(srcPathName, name)\n",
    "                    else:\n",
    "                        name = \"pos/\"+str(pic_num)+\".png\"\n",
    "                        os.rename(srcPathName, name)\n",
    "                    img = cv2.imread(name,cv2.IMREAD_GRAYSCALE)\n",
    "                    img = img[int(x2):int(y2), int(x1):int(y1)]\n",
    "                    # should be larger than samples / pos pic (so we can place our image on it)\n",
    "                    resized_image = cv2.resize(img, (50, 50))\n",
    "                    os.remove(name)\n",
    "                    cv2.imwrite(name,resized_image)\n",
    "                    print(pic_num)\n",
    "                    pic_num += 1\n",
    "                \n",
    "                except Exception as e:\n",
    "                    print(str(e))  \n",
    "\n",
    "\n",
    "\n",
    "store_raw_images()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "secure-horizon",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "from csv import reader\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def store_raw_images():\n",
    "    neg_image_urls = open(\"bg.txt\",'r')\n",
    "    pic_num = 1\n",
    "    name = \"\"    \n",
    "    if not os.path.exists('neg'):\n",
    "        os.makedirs('neg')\n",
    "        \n",
    "    with open(\"bg.txt\",'r') as read_obj:\n",
    "        # pass the file object to reader() to get the reader object\n",
    "        csv_reader = reader(read_obj)\n",
    "        # Iterate over each row in the csv using reader object\n",
    "        for i in csv_reader:\n",
    "            for j in i[0].split(\".\"):\n",
    "                i[0] = i[0].strip()\n",
    "                j=j.strip() # remove space\n",
    "                if pic_num == 1: # cus i testet first\n",
    "                    pic_num += 1\n",
    "                    continue\n",
    "                if len(j)>4:\n",
    "                    continue\n",
    "                try:\n",
    "                    print(i[0])\n",
    "                    if j == 'jpg':\n",
    "                        name = \"neg/\"+str(pic_num)+\".jpg\"\n",
    "                        os.rename(i[0], name)\n",
    "                    else:\n",
    "                        name = \"neg/\"+str(pic_num)+\".png\"\n",
    "                        os.rename(i[0], name)\n",
    "                    img = cv2.imread(name,cv2.IMREAD_GRAYSCALE)\n",
    "                    # should be larger than samples / pos pic (so we can place our image on it)\n",
    "                    resized_image = cv2.resize(img, (100, 100))\n",
    "                    os.remove(name)\n",
    "                    cv2.imwrite(name,resized_image)\n",
    "                    print(pic_num)\n",
    "                    pic_num += 1\n",
    "                \n",
    "                except Exception as e:\n",
    "                    print(str(e))  \n",
    "\n",
    "\n",
    "\n",
    "store_raw_images()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "united-county",
   "metadata": {},
   "source": [
    "    Then we update bg / info files to create our haar cascade with the new data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "irish-funeral",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "f=open('info.dat', 'w')\n",
    "def update_info():\n",
    "    pos_images_dir = 'F:\\MLBig\\Creating_VJ_Cascade\\pos'\n",
    "    for filename in os.listdir(pos_images_dir):\n",
    "        num = filename.split('.')[ 0 ]\n",
    "        # first param how many objects then x,y,x+w,y+h\n",
    "        #since we cut face its the entire img\n",
    "        f.write('pos/' + filename + ' 1 0 0 50 50 \\n')\n",
    "        print(num)\n",
    "    f.close()\n",
    "\n",
    "update_info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "productive-release",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "f=open('bg.txt', 'w')\n",
    "def update_bg():\n",
    "    neg_images_dir = 'F:\\\\MLBig\\\\Creating_VJ_Cascade\\\\neg'\n",
    "    for filename in os.listdir(neg_images_dir):\n",
    "        num = filename.split('.')[ 0 ]\n",
    "        f.write('neg/' + filename + ' \\n')\n",
    "        print(num)\n",
    "    f.close()\n",
    "\n",
    "update_bg()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "recorded-links",
   "metadata": {},
   "source": [
    "    we train in Linux according to the guide https://pythonprogramming.net/haar-cascade-object-detection-python-opencv-tutorial/\n",
    "    (opencv_traincascade command in linux)\n",
    "    the following code opens your camera and draw rect in diffrent colors if ur wearing mask / no mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "existing-transfer",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "face_cascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "\n",
    "#this is the cascade we just made. Call what you want\n",
    "mask_cascade = cv2.CascadeClassifier('mask_cascade_1.xml')\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while 1:\n",
    "    ret, img = cap.read()\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_cascade.detectMultiScale(gray, 1.3, 5)\n",
    "    \n",
    "    # add this\n",
    "    # image, reject levels level weights.\n",
    "    maskes = mask_cascade.detectMultiScale(gray,1.3,20)# 1.3,20\n",
    "    \n",
    "    # add this\n",
    "\n",
    "\n",
    "    for (x,y,w,h) in faces:\n",
    "        print(\"(\"+str(x)+','+str(y)+'),('+str(x+w)+','+str(y+h)+')')\n",
    "        cv2.rectangle(img,(x,y),(x+w,y+h),(255,0,0),2)\n",
    "\n",
    "\n",
    "        \n",
    "        roi_gray = gray[y:y+h, x:x+w]\n",
    "        roi_color = img[y:y+h, x:x+w]    \n",
    "    for (x,y,w,h) in maskes:\n",
    "        cv2.rectangle(img,(x,y),(x+w,y+h),(255,255,0),2)\n",
    "\n",
    "\n",
    "    cv2.imshow('img',img)\n",
    "    k = cv2.waitKey(30) & 0xff\n",
    "    if k == 27:\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "extensive-shaft",
   "metadata": {},
   "source": [
    "    I get alot of falses and I dont like this solution.\n",
    "    Therefore we try again training on 224x224 images.\n",
    "    increasing the stages from 10 to 15\n",
    "    I'm not testing this model since its really not accurate."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "postal-literature",
   "metadata": {},
   "source": [
    "SECOND ATTEMT TO CREATE haar cascade classifier for faceMask detection\n",
    "----------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "electoral-detector",
   "metadata": {},
   "source": [
    "    we changed the generate data code to fit this specific model here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hungarian-athens",
   "metadata": {},
   "outputs": [],
   "source": [
    "images=[]\n",
    "labels=[]\n",
    "\n",
    "f=open('info.dat', 'w')\n",
    "fb = open('bg.txt', 'w')\n",
    "poscounter=1\n",
    "negcounter=1\n",
    "masked_img  = False\n",
    "for filename in os.listdir(images_dir):\n",
    "    num = filename.split('.')[ 0 ]\n",
    "    print(\"loading image: {}\".format(filename))\n",
    "    if int(num) > 1800:\n",
    "        class_name = None\n",
    "        anno = filename + \".json\"\n",
    "        with open(os.path.join(anno_dir, anno)) as json_file:\n",
    "            json_data = json.load(json_file)\n",
    "            no_anno = json_data[\"NumOfAnno\"]\n",
    "            k = 0\n",
    "            for i in range(0, no_anno):\n",
    "                class_nam = json_data['Annotations'][i]['classname']\n",
    "                if class_nam in ['face_with_mask', \"mask_surgical\", \"mask_colorful\"]:\n",
    "                    class_name = 'face_with_mask'\n",
    "                    k = i\n",
    "                    masked_img = True\n",
    "                    break\n",
    "                elif class_nam in ['face_no_mask,\"hijab_niqab', 'face_other_covering', \"face_with_mask_incorrect\", \"scarf_bandana\",\"balaclava_ski_mask\", \"other\" ]:                   \n",
    "                    class_name = 'face_no_mask'\n",
    "                    k = i\n",
    "                    masked_img = False\n",
    "                    break\n",
    "                else:\n",
    "                    continue\n",
    "                    \n",
    "            box = json_data[ 'Annotations' ][k][ 'BoundingBox' ]\n",
    "            (x1, x2, y1, y2) = box\n",
    "            print('point:'+str(x1)+','+str(x2)+','+str(y1)+','+str(y2))\n",
    "            # pathes on linux syntax since train is on linux.\n",
    "            if masked_img:\n",
    "                #f.write('pos/' + filename + ' 1 ' + str(x1) + ' ' + str(x2) + ' ' +  str(y1) + ' ' + str(y2) + ' \\n')\n",
    "                f.write('pos/' + str(poscounter) + ' 1 0 0 224 224 \\n')\n",
    "            else:\n",
    "                fb.write('neg/' + str(negcounter) + ' \\n')\n",
    "        if class_name is not None: # we ignore some faces here\n",
    "            image = cv2.imread(os.path.join(images_dir, filename),cv2.IMREAD_GRAYSCALE)\n",
    "            img = image[x2:y2, x1:y1]\n",
    "            img = cv2.resize(img, (224, 224))\n",
    "            images.append(img)\n",
    "            labels.append(class_name)  \n",
    "            if masked_img:\n",
    "                if filename.split('.')[ 1 ] == 'jpeg':\n",
    "                    print('pos\\\\'+str(poscounter)+\".\"+filename.split('.')[ 1 ])\n",
    "                    cv2.imwrite('pos\\\\'+str(poscounter)+\".\"+'jpg',img)\n",
    "                    poscounter += 1\n",
    "                else:\n",
    "                    print('pos\\\\'+str(poscounter)+\".\"+filename.split('.')[ 1 ])\n",
    "                    cv2.imwrite('pos\\\\'+str(poscounter)+\".\"+filename.split('.')[ 1 ],img)\n",
    "                    poscounter += 1\n",
    "            else:\n",
    "                if filename.split('.')[ 1 ] == 'jpeg':\n",
    "                    print('neg\\\\'+str(negcounter)+\".\"+filename.split('.')[ 1 ])\n",
    "                    cv2.imwrite('neg\\\\'+str(negcounter)+\".\"+'jpg',img)\n",
    "                    negcounter += 1\n",
    "                else:\n",
    "                    print('neg\\\\'+str(negcounter)+\".\"+filename.split('.')[ 1 ])\n",
    "                    cv2.imwrite('neg\\\\'+str(negcounter)+\".\"+filename.split('.')[ 1 ],img)\n",
    "                    negcounter += 1\n",
    "\n",
    "   \n",
    "f.close()\n",
    "fb.close()\n",
    "images = np.array(images, dtype=\"float32\")\n",
    "labels = np.array(labels)\n",
    "print(len(images))\n",
    "print(len(labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "southwest-strip",
   "metadata": {},
   "source": [
    "    we train in Linux according to the guide https://pythonprogramming.net/haar-cascade-object-detection-python-opencv-tutorial/\n",
    "    the following code opens your camera and draw rect in diffrent colors if ur wearing mask / no mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "orange-metropolitan",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "face_cascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "\n",
    "#this is the cascade we just made. Call what you want\n",
    "watch_cascade = cv2.CascadeClassifier('mask_cascade_2.xml')\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while 1:\n",
    "    ret, img = cap.read()\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_cascade.detectMultiScale(gray, 1.3, 5)\n",
    "    \n",
    "    # add this\n",
    "    # image, reject levels level weights.\n",
    "    watches = watch_cascade.detectMultiScale(gray,1.3,20)# 1.3,20\n",
    "    \n",
    "    # add this\n",
    "\n",
    "\n",
    "    for (x,y,w,h) in faces:\n",
    "        cv2.rectangle(img,(x,y),(x+w,y+h),(255,0,0),2)\n",
    "\n",
    "\n",
    "        \n",
    "        roi_gray = gray[y:y+h, x:x+w]\n",
    "        roi_color = img[y:y+h, x:x+w]    \n",
    "    for (x,y,w,h) in watches:\n",
    "        cv2.rectangle(img,(x,y),(x+w,y+h),(255,255,0),2)\n",
    "\n",
    "\n",
    "    cv2.imshow('img',img)\n",
    "    k = cv2.waitKey(30) & 0xff\n",
    "    if k == 27:\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "endless-springfield",
   "metadata": {},
   "source": [
    "    better but still not good enough\n",
    "    model evaluation: 100 pos images + 100 neg images through my webcam at night"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "global-clarity",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Counter\n",
    "import numpy as np\n",
    "import cv2\n",
    "import time\n",
    "\n",
    "face_cascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "\n",
    "#this is the cascade we just made. Call what you want\n",
    "mask_cascade = cv2.CascadeClassifier('mask_cascade_2.xml')\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "pos_counter = 0\n",
    "iter_counter = 0\n",
    "neg_counter = 0\n",
    "\n",
    "while 1:\n",
    "    ret, img = cap.read()\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_cascade.detectMultiScale(gray, 1.3, 5)\n",
    "    \n",
    "    # add this\n",
    "    # image, reject levels level weights.\n",
    "    \"\"\"\"\"\n",
    "    Try diffrent Params in diff light / brightness / face size (if far or close)\n",
    "    \"\"\"\n",
    "    masks = mask_cascade.detectMultiScale(gray,1.34,18) \n",
    "    #FOR RAB:\n",
    "    #1.3, 15 WORK WELL\n",
    "    \n",
    "    #1.3 19 Seems best in tomer's conditions at night.\n",
    "    #1.3,11 DOESNT WORK FOR UNCOVER NOSE WELL BUT DECENT\n",
    "    #GAB 1.3 19 Seems decent (PROB NOT RAB)\n",
    "    \n",
    "    # GAB\n",
    "    # 1.6,30 224x224 (24x24)   # 1.3,20\n",
    "    \n",
    "    # add this\n",
    "    masked = True\n",
    "\n",
    "    for (x,y,w,h) in faces:\n",
    "        cv2.rectangle(img,(x,y),(x+w,y+h),(0,0,255),2)\n",
    "        masked = False\n",
    "\n",
    "\n",
    "        \n",
    "        roi_gray = gray[y:y+h, x:x+w]\n",
    "        roi_color = img[y:y+h, x:x+w]    \n",
    "    for (x,y,w,h) in masks:\n",
    "        masked = True\n",
    "        cv2.putText(img,'Mask',(x,y-10), cv2.FONT_HERSHEY_SIMPLEX, 1,(255, 255, 0),4)#((x*2+w)/2,(y*2+h)/2)\n",
    "        cv2.rectangle(img,(x,y),(x+w,y+h),(255,255,0),2)\n",
    "    # if haarcascade_frontalface_default.xml detects face but our didnt we put txt no mask\n",
    "    if not masked:\n",
    "        cv2.putText(img,'No mask',(x,y-10), cv2.FONT_HERSHEY_SIMPLEX, 1,(0, 0, 255),4)#((x*2+w)/2,(y*2+h)/2)\n",
    "    iter_counter += 1 \n",
    "    if masked:\n",
    "        pos_counter += 1\n",
    "    if iter_counter == 100:\n",
    "        break\n",
    "    print(str(iter_counter))\n",
    "    cv2.imshow('img',img)\n",
    "    k = cv2.waitKey(30) & 0xff\n",
    "    if k == 27:\n",
    "        break\n",
    "\n",
    "time.sleep(10)\n",
    "\n",
    "while 1:\n",
    "    ret, img = cap.read()\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_cascade.detectMultiScale(gray, 1.3, 5)\n",
    "    \n",
    "    # add this\n",
    "    # image, reject levels level weights.\n",
    "    \"\"\"\"\"\n",
    "    Try diffrent Params in diff light / brightness / face size (if far or close)\n",
    "    \"\"\"\n",
    "    masks = mask_cascade.detectMultiScale(gray,1.3,19) \n",
    "    #FOR RAB:\n",
    "    #1.3, 15 WORK WELL\n",
    "    \n",
    "    #1.3 19 Seems best in tomer's conditions at night.\n",
    "    #1.3,11 DOESNT WORK FOR UNCOVER NOSE WELL BUT DECENT\n",
    "    #GAB 1.3 19 Seems decent (PROB NOT RAB)\n",
    "    \n",
    "    # GAB\n",
    "    # 1.6,30 224x224 (24x24)   # 1.3,20\n",
    "    \n",
    "    # add this\n",
    "    masked = True\n",
    "\n",
    "    for (x,y,w,h) in faces:\n",
    "        cv2.rectangle(img,(x,y),(x+w,y+h),(0,0,255),2)\n",
    "        masked = False\n",
    "\n",
    "\n",
    "        \n",
    "        roi_gray = gray[y:y+h, x:x+w]\n",
    "        roi_color = img[y:y+h, x:x+w]    \n",
    "    for (x,y,w,h) in masks:\n",
    "        masked = True\n",
    "        cv2.putText(img,'Mask',(x,y-10), cv2.FONT_HERSHEY_SIMPLEX, 1,(255, 255, 0),4)#((x*2+w)/2,(y*2+h)/2)\n",
    "        cv2.rectangle(img,(x,y),(x+w,y+h),(255,255,0),2)\n",
    "    # if haarcascade_frontalface_default.xml detects face but our didnt we put txt no mask\n",
    "    if not masked:\n",
    "        cv2.putText(img,'No mask',(x,y-10), cv2.FONT_HERSHEY_SIMPLEX, 1,(0, 0, 255),4)#((x*2+w)/2,(y*2+h)/2)\n",
    "    iter_counter += 1 \n",
    "    if not masked:\n",
    "        neg_counter += 1\n",
    "    if iter_counter == 200:\n",
    "        break\n",
    "    cv2.imshow('img',img)\n",
    "    k = cv2.waitKey(30) & 0xff\n",
    "    if k == 27:\n",
    "        break\n",
    "    print(str(iter_counter))\n",
    "\n",
    "score = (neg_counter+pos_counter)/iter_counter\n",
    "print(score)\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "expanded-programming",
   "metadata": {},
   "source": [
    "TEST ACC: 0.88"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "religious-catch",
   "metadata": {},
   "source": [
    "THIRD ATTEMT TO CREATE haar cascade classifier for faceMask detection\n",
    "----------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "extraordinary-witch",
   "metadata": {},
   "source": [
    "    here were increasing to 15 stages\n",
    "    files size increased to 224_224\n",
    "    the training is on 120 width 100 height to fit my camera\n",
    "    Ofc we handle the data first I didnt changed the code so i didnt coppied it"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "understood-wallet",
   "metadata": {},
   "source": [
    "    You can skip this note\n",
    "\n",
    "    (Some Numerical info and why I chose these params:)\n",
    "\n",
    "\"\"\"\"\"\n",
    "Conclusion:\n",
    "\n",
    "cascade tarined as HAAR\n",
    "\n",
    "-v-HAAR classifiers are very accurate but require a lot more time to train\n",
    "-x-LBP classifiers on the other hand are less accurate but train much quicker and detect almost 3 times faster.\n",
    "\n",
    "-mode <BASIC (default) | CORE | ALL> : Selects the type of Haar features set used in training. BASIC use only upright features, while ALL uses the full set of upright and 45 degree rotated feature set. See [148] for more details.\n",
    "---> BASIC done, try ALL\n",
    "\n",
    "Adaboost PARAMS\n",
    "---> value + explain:\n",
    "\n",
    "-acceptanceRatioBreakValue <break_value> : This argument is used to determine how precise your model should keep learning and when to stop. A good guideline is to train not further than 10e-5, to ensure the model does not overtrain on your training data. By default this value is set to -1 to disable this feature.\n",
    "---> -1, we dont need this since we dont have unlimited time.\n",
    "\n",
    "-Boost type: GAB (Gentle Adaboost)\n",
    "for params explain: https://topic.alibabacloud.com/a/comparison-of-several-boost-algorithms-discrete-adaboost-real-adaboost-logitboost-gentle-adaboost-__-machine-learning_8_8_20288852.html\n",
    "-weightTrimRate <weight_trim_rate> : Specifies whether trimming should be used and its weight. A decent choice is 0.95.\n",
    "---> 0.95\n",
    "-maxDepth <max_depth_of_weak_tree> : Maximal depth of a weak tree. A decent choice is 1, that is case of stumps.\n",
    "---> 1\n",
    "-maxFalseAlarmRate <max_false_alarm_rate> : Maximal desired false alarm rate for each stage of the classifier. Overall false alarm rate may be estimated as (max_false_alarm_rate ^ number_of_stages)\n",
    "---> 0.5^15 / 0.5^25 (FA - 0.5, Stages - 15 / 25) small nums decent choise (may wanna try lower if i have more time)\n",
    "-maxWeakCount <max_weak_tree_count> : Maximal count of weak trees for every cascade stage. The boosted classifier (stage) will have so many weak trees (<=maxWeakCount), as needed to achieve the given -maxFalseAlarmRate.\n",
    "---> 100 by default choise (may wanna try more options if i have more time)\n",
    "\n",
    "neg img: 1082\n",
    "pos img: 69% * 2600\n",
    "\n",
    "changed: 224x224 train pic the detection is 24x24\n",
    "\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "permanent-mathematics",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "face_cascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "\n",
    "#this is the cascade we just made. Call what you want\n",
    "mask_cascade = cv2.CascadeClassifier('mask_cascade.xml')\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while 1:\n",
    "    ret, img = cap.read()\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_cascade.detectMultiScale(gray, 1.3, 5)\n",
    "    \n",
    "    # add this\n",
    "    # image, reject levels level weights.\n",
    "    masks = mask_cascade.detectMultiScale(gray,1.6,25)# 1.6,30 224x224 (24x24)   # 1.3,20\n",
    "    \n",
    "    # add this\n",
    "\n",
    "\n",
    "    for (x,y,w,h) in faces:\n",
    "        cv2.rectangle(img,(x,y),(x+w,y+h),(255,0,0),2)\n",
    "\n",
    "\n",
    "        \n",
    "        roi_gray = gray[y:y+h, x:x+w]\n",
    "        roi_color = img[y:y+h, x:x+w]    \n",
    "    for (x,y,w,h) in masks:\n",
    "        cv2.rectangle(img,(x,y),(x+w,y+h),(255,255,0),2)\n",
    "\n",
    "\n",
    "    cv2.imshow('img',img)\n",
    "    k = cv2.waitKey(30) & 0xff\n",
    "    if k == 27:\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "behind-islam",
   "metadata": {},
   "source": [
    "    this starts to look decent and we think about where we still wanna improve now\n",
    "    lets evaluate the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "knowing-arctic",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Counter\n",
    "import numpy as np\n",
    "import cv2\n",
    "import time\n",
    "\n",
    "face_cascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "\n",
    "#this is the cascade we just made. Call what you want\n",
    "mask_cascade = cv2.CascadeClassifier('mask_cascade.xml')\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "pos_counter = 0\n",
    "iter_counter = 0\n",
    "neg_counter = 0\n",
    "\n",
    "while 1:\n",
    "    ret, img = cap.read()\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_cascade.detectMultiScale(gray, 1.3, 5)\n",
    "    \n",
    "    # add this\n",
    "    # image, reject levels level weights.\n",
    "    \"\"\"\"\"\n",
    "    Try diffrent Params in diff light / brightness / face size (if far or close)\n",
    "    \"\"\"\n",
    "    masks = mask_cascade.detectMultiScale(gray,1.34,18) \n",
    "    #FOR RAB:\n",
    "    #1.3, 15 WORK WELL\n",
    "    \n",
    "    #1.3 19 Seems best in tomer's conditions at night.\n",
    "    #1.3,11 DOESNT WORK FOR UNCOVER NOSE WELL BUT DECENT\n",
    "    #GAB 1.3 19 Seems decent (PROB NOT RAB)\n",
    "    \n",
    "    # GAB\n",
    "    # 1.6,30 224x224 (24x24)   # 1.3,20\n",
    "    \n",
    "    # add this\n",
    "    masked = True\n",
    "\n",
    "    for (x,y,w,h) in faces:\n",
    "        cv2.rectangle(img,(x,y),(x+w,y+h),(0,0,255),2)\n",
    "        masked = False\n",
    "\n",
    "\n",
    "        \n",
    "        roi_gray = gray[y:y+h, x:x+w]\n",
    "        roi_color = img[y:y+h, x:x+w]    \n",
    "    for (x,y,w,h) in masks:\n",
    "        masked = True\n",
    "        cv2.putText(img,'Mask',(x,y-10), cv2.FONT_HERSHEY_SIMPLEX, 1,(255, 255, 0),4)#((x*2+w)/2,(y*2+h)/2)\n",
    "        cv2.rectangle(img,(x,y),(x+w,y+h),(255,255,0),2)\n",
    "    # if haarcascade_frontalface_default.xml detects face but our didnt we put txt no mask\n",
    "    if not masked:\n",
    "        cv2.putText(img,'No mask',(x,y-10), cv2.FONT_HERSHEY_SIMPLEX, 1,(0, 0, 255),4)#((x*2+w)/2,(y*2+h)/2)\n",
    "    iter_counter += 1 \n",
    "    if masked:\n",
    "        pos_counter += 1\n",
    "    if iter_counter == 100:\n",
    "        break\n",
    "    print(str(iter_counter))\n",
    "    cv2.imshow('img',img)\n",
    "    k = cv2.waitKey(30) & 0xff\n",
    "    if k == 27:\n",
    "        break\n",
    "\n",
    "time.sleep(10)\n",
    "\n",
    "while 1:\n",
    "    ret, img = cap.read()\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_cascade.detectMultiScale(gray, 1.3, 5)\n",
    "    \n",
    "    # add this\n",
    "    # image, reject levels level weights.\n",
    "    \"\"\"\"\"\n",
    "    Try diffrent Params in diff light / brightness / face size (if far or close)\n",
    "    \"\"\"\n",
    "    masks = mask_cascade.detectMultiScale(gray,1.3,19) \n",
    "    #FOR RAB:\n",
    "    #1.3, 15 WORK WELL\n",
    "    \n",
    "    #1.3 19 Seems best in tomer's conditions at night.\n",
    "    #1.3,11 DOESNT WORK FOR UNCOVER NOSE WELL BUT DECENT\n",
    "    #GAB 1.3 19 Seems decent (PROB NOT RAB)\n",
    "    \n",
    "    # GAB\n",
    "    # 1.6,30 224x224 (24x24)   # 1.3,20\n",
    "    \n",
    "    # add this\n",
    "    masked = True\n",
    "\n",
    "    for (x,y,w,h) in faces:\n",
    "        cv2.rectangle(img,(x,y),(x+w,y+h),(0,0,255),2)\n",
    "        masked = False\n",
    "\n",
    "\n",
    "        \n",
    "        roi_gray = gray[y:y+h, x:x+w]\n",
    "        roi_color = img[y:y+h, x:x+w]    \n",
    "    for (x,y,w,h) in masks:\n",
    "        masked = True\n",
    "        cv2.putText(img,'Mask',(x,y-10), cv2.FONT_HERSHEY_SIMPLEX, 1,(255, 255, 0),4)#((x*2+w)/2,(y*2+h)/2)\n",
    "        cv2.rectangle(img,(x,y),(x+w,y+h),(255,255,0),2)\n",
    "    # if haarcascade_frontalface_default.xml detects face but our didnt we put txt no mask\n",
    "    if not masked:\n",
    "        cv2.putText(img,'No mask',(x,y-10), cv2.FONT_HERSHEY_SIMPLEX, 1,(0, 0, 255),4)#((x*2+w)/2,(y*2+h)/2)\n",
    "    iter_counter += 1 \n",
    "    if not masked:\n",
    "        neg_counter += 1\n",
    "    if iter_counter == 200:\n",
    "        break\n",
    "    cv2.imshow('img',img)\n",
    "    k = cv2.waitKey(30) & 0xff\n",
    "    if k == 27:\n",
    "        break\n",
    "    print(str(iter_counter))\n",
    "\n",
    "score = (neg_counter+pos_counter)/iter_counter\n",
    "print(score)\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bridal-glory",
   "metadata": {},
   "source": [
    "Test ACC: 93"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "manufactured-disaster",
   "metadata": {},
   "source": [
    "Fourth ATTEMT TO CREATE haar cascade classifier for faceMask detection\n",
    "----------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "exterior-occupation",
   "metadata": {},
   "source": [
    "    at this model we tried the following params\n",
    "    files size increased to 224x224\n",
    "    the training is on 24 width 24 height to match original VJ\n",
    "    training methods changed:\n",
    "    stages: 25\n",
    "    mode: ALL\n",
    "    neg img: 900\n",
    "    pos img: 1800\n",
    "    Boost type: RAB (Real Adaboost)\n",
    "\n",
    "    TEST ACC (200 images): 0.97%"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "handed-luxembourg",
   "metadata": {},
   "source": [
    "    clean the DS from curropted img\n",
    "    if class_nam in ['face_with_mask',\"gas_mask\", \"face_shield\", \"mask_surgical\", \"mask_colorful\"]:\n",
    "     changed to:\n",
    "      if class_nam in ['face_with_mask', \"mask_surgical\", \"mask_colorful\"]:\n",
    "\n",
    "    to pass bad images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "general-protein",
   "metadata": {},
   "outputs": [],
   "source": [
    "images=[]\n",
    "labels=[]\n",
    "\n",
    "f=open('info.dat', 'w')\n",
    "fb = open('bg.txt', 'w')\n",
    "poscounter=1\n",
    "negcounter=1\n",
    "masked_img  = False\n",
    "for filename in os.listdir(images_dir):\n",
    "    num = filename.split('.')[ 0 ]\n",
    "    print(\"loading image: {}\".format(filename))\n",
    "    if int(num) > 1800:\n",
    "        class_name = None\n",
    "        anno = filename + \".json\"\n",
    "        with open(os.path.join(anno_dir, anno)) as json_file:\n",
    "            json_data = json.load(json_file)\n",
    "            no_anno = json_data[\"NumOfAnno\"]\n",
    "            k = 0\n",
    "            for i in range(0, no_anno):\n",
    "                class_nam = json_data['Annotations'][i]['classname']\n",
    "                if class_nam in ['face_with_mask', \"mask_surgical\", \"mask_colorful\"]:\n",
    "                    class_name = 'face_with_mask'\n",
    "                    k = i\n",
    "                    masked_img = True\n",
    "                    break\n",
    "                elif class_nam in ['face_no_mask,\"hijab_niqab', 'face_other_covering', \"face_with_mask_incorrect\", \"scarf_bandana\",\"balaclava_ski_mask\", \"other\" ]:                   \n",
    "                    class_name = 'face_no_mask'\n",
    "                    k = i\n",
    "                    masked_img = False\n",
    "                    break\n",
    "                else:\n",
    "                    continue\n",
    "                    \n",
    "            box = json_data[ 'Annotations' ][k][ 'BoundingBox' ]\n",
    "            (x1, x2, y1, y2) = box\n",
    "            print('point:'+str(x1)+','+str(x2)+','+str(y1)+','+str(y2))\n",
    "            # pathes on linux syntax since train is on linux.\n",
    "            if masked_img:\n",
    "                #f.write('pos/' + filename + ' 1 ' + str(x1) + ' ' + str(x2) + ' ' +  str(y1) + ' ' + str(y2) + ' \\n')\n",
    "                f.write('pos/' + str(poscounter) + ' 1 0 0 224 224 \\n')\n",
    "            else:\n",
    "                fb.write('neg/' + str(negcounter) + ' \\n')\n",
    "        if class_name is not None: # we ignore some faces here\n",
    "            image = cv2.imread(os.path.join(images_dir, filename),cv2.IMREAD_GRAYSCALE)\n",
    "            img = image[x2:y2, x1:y1]\n",
    "            img = cv2.resize(img, (224, 224))\n",
    "            images.append(img)\n",
    "            labels.append(class_name)  \n",
    "            if masked_img:\n",
    "                if filename.split('.')[ 1 ] == 'jpeg':\n",
    "                    print('pos\\\\'+str(poscounter)+\".\"+filename.split('.')[ 1 ])\n",
    "                    cv2.imwrite('pos\\\\'+str(poscounter)+\".\"+'jpg',img)\n",
    "                    poscounter += 1\n",
    "                else:\n",
    "                    print('pos\\\\'+str(poscounter)+\".\"+filename.split('.')[ 1 ])\n",
    "                    cv2.imwrite('pos\\\\'+str(poscounter)+\".\"+filename.split('.')[ 1 ],img)\n",
    "                    poscounter += 1\n",
    "            else:\n",
    "                if filename.split('.')[ 1 ] == 'jpeg':\n",
    "                    print('neg\\\\'+str(negcounter)+\".\"+filename.split('.')[ 1 ])\n",
    "                    cv2.imwrite('neg\\\\'+str(negcounter)+\".\"+'jpg',img)\n",
    "                    negcounter += 1\n",
    "                else:\n",
    "                    print('neg\\\\'+str(negcounter)+\".\"+filename.split('.')[ 1 ])\n",
    "                    cv2.imwrite('neg\\\\'+str(negcounter)+\".\"+filename.split('.')[ 1 ],img)\n",
    "                    negcounter += 1\n",
    "\n",
    "   \n",
    "f.close()\n",
    "fb.close()\n",
    "images = np.array(images, dtype=\"float32\")\n",
    "labels = np.array(labels)\n",
    "print(len(images))\n",
    "print(len(labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fossil-passion",
   "metadata": {},
   "source": [
    "    can pass this numerical info why i changed what i changed:\n",
    "\n",
    "\"\"\"\"\"\n",
    "Conclusion:\n",
    "\n",
    "cascade tarined as HAAR\n",
    "\n",
    "-v-HAAR classifiers are very accurate but require a lot more time to train\n",
    "-x-LBP classifiers on the other hand are less accurate but train much quicker and detect almost 3 times faster.\n",
    "\n",
    "-mode <BASIC (default) | CORE | ALL> : Selects the type of Haar features set used in training. BASIC use only upright features, while ALL uses the full set of upright and 45 degree rotated feature set. See [148] for more details.\n",
    "---> BASIC done, try ALL\n",
    "\n",
    "Adaboost PARAMS\n",
    "---> value + explain:\n",
    "\n",
    "-acceptanceRatioBreakValue <break_value> : This argument is used to determine how precise your model should keep learning and when to stop. A good guideline is to train not further than 10e-5, to ensure the model does not overtrain on your training data. By default this value is set to -1 to disable this feature.\n",
    "---> -1, we dont need this since we dont have unlimited time.\n",
    "\n",
    "-Boost type: GAB (Gentle Adaboost)\n",
    "for params explain: https://topic.alibabacloud.com/a/comparison-of-several-boost-algorithms-discrete-adaboost-real-adaboost-logitboost-gentle-adaboost-__-machine-learning_8_8_20288852.html\n",
    "-weightTrimRate <weight_trim_rate> : Specifies whether trimming should be used and its weight. A decent choice is 0.95.\n",
    "---> 0.95\n",
    "-maxDepth <max_depth_of_weak_tree> : Maximal depth of a weak tree. A decent choice is 1, that is case of stumps.\n",
    "---> 1\n",
    "-maxFalseAlarmRate <max_false_alarm_rate> : Maximal desired false alarm rate for each stage of the classifier. Overall false alarm rate may be estimated as (max_false_alarm_rate ^ number_of_stages)\n",
    "---> 0.5^15 / 0.5^25 (FA - 0.5, Stages - 15 / 25) small nums decent choise (may wanna try lower if i have more time)\n",
    "-maxWeakCount <max_weak_tree_count> : Maximal count of weak trees for every cascade stage. The boosted classifier (stage) will have so many weak trees (<=maxWeakCount), as needed to achieve the given -maxFalseAlarmRate.\n",
    "---> 100 by default choise (may wanna try more options if i have more time)\n",
    "\n",
    "neg img: 1082\n",
    "pos img: 69% * 2600\n",
    "\n",
    "changed: 224x224 train pic the detection is 24x24\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "frozen-canadian",
   "metadata": {},
   "source": [
    "Real time test with webcam:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "complicated-charge",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "face_cascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "\n",
    "#this is the cascade we just made. Call what you want\n",
    "mask_cascade = cv2.CascadeClassifier('mask_cascade_RAB_ALL.xml')\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while 1:\n",
    "    ret, img = cap.read()\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_cascade.detectMultiScale(gray, 1.3, 5)\n",
    "    \n",
    "    # add this\n",
    "    # image, reject levels level weights.\n",
    "    masks = mask_cascade.detectMultiScale(gray,1.6,25)# 1.6,30 224x224 (24x24)   # 1.3,20\n",
    "    \n",
    "    # add this\n",
    "\n",
    "\n",
    "    for (x,y,w,h) in faces:\n",
    "        cv2.rectangle(img,(x,y),(x+w,y+h),(255,0,0),2)\n",
    "\n",
    "\n",
    "        \n",
    "        roi_gray = gray[y:y+h, x:x+w]\n",
    "        roi_color = img[y:y+h, x:x+w]    \n",
    "    for (x,y,w,h) in masks:\n",
    "        cv2.rectangle(img,(x,y),(x+w,y+h),(255,255,0),2)\n",
    "\n",
    "\n",
    "    cv2.imshow('img',img)\n",
    "    k = cv2.waitKey(30) & 0xff\n",
    "    if k == 27:\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "romance-mouse",
   "metadata": {},
   "source": [
    "    solution felt good and accurate on real time therefore we evaluate our accuracy now :)\n",
    "\n",
    "    we take 100 images with mask each image iter_counter+=1 if mask detect pos_counter += 1\n",
    "    we take 100 images without mask each image iter_counter+=1 if mask detect neg_counter += 1\n",
    "    then we give score by (pos_counter+neg_counter)/iter_counter ==> 0.97"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "thorough-medline",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Counter\n",
    "import numpy as np\n",
    "import cv2\n",
    "import time\n",
    "\n",
    "face_cascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "\n",
    "#this is the cascade we just made. Call what you want\n",
    "mask_cascade = cv2.CascadeClassifier('mask_cascade_RAB_ALL.xml')\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "pos_counter = 0\n",
    "iter_counter = 0\n",
    "neg_counter = 0\n",
    "\n",
    "while 1:\n",
    "    ret, img = cap.read()\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_cascade.detectMultiScale(gray, 1.3, 5)\n",
    "    \n",
    "    # add this\n",
    "    # image, reject levels level weights.\n",
    "    \"\"\"\"\"\n",
    "    Try diffrent Params in diff light / brightness / face size (if far or close)\n",
    "    \"\"\"\n",
    "    masks = mask_cascade.detectMultiScale(gray,1.3,8) \n",
    "    #FOR RAB:\n",
    "    #1.3, 15 WORK WELL\n",
    "    \n",
    "    #1.3 19 Seems best in tomer's conditions at night.\n",
    "    #1.3,11 DOESNT WORK FOR UNCOVER NOSE WELL BUT DECENT\n",
    "    #GAB 1.3 19 Seems decent (PROB NOT RAB)\n",
    "    \n",
    "    # GAB\n",
    "    # 1.6,30 224x224 (24x24)   # 1.3,20\n",
    "    \n",
    "    # add this\n",
    "    masked = True\n",
    "\n",
    "    for (x,y,w,h) in faces:\n",
    "        cv2.rectangle(img,(x,y),(x+w,y+h),(0,0,255),2)\n",
    "        masked = False\n",
    "\n",
    "\n",
    "        \n",
    "        roi_gray = gray[y:y+h, x:x+w]\n",
    "        roi_color = img[y:y+h, x:x+w]    \n",
    "    for (x,y,w,h) in masks:\n",
    "        masked = True\n",
    "        cv2.putText(img,'Mask',(x,y-10), cv2.FONT_HERSHEY_SIMPLEX, 1,(255, 255, 0),4)#((x*2+w)/2,(y*2+h)/2)\n",
    "        cv2.rectangle(img,(x,y),(x+w,y+h),(255,255,0),2)\n",
    "    # if haarcascade_frontalface_default.xml detects face but our didnt we put txt no mask\n",
    "    if not masked:\n",
    "        cv2.putText(img,'No mask',(x,y-10), cv2.FONT_HERSHEY_SIMPLEX, 1,(0, 0, 255),4)#((x*2+w)/2,(y*2+h)/2)\n",
    "    iter_counter += 1 \n",
    "    if masked:\n",
    "        pos_counter += 1\n",
    "    if iter_counter == 100:\n",
    "        break\n",
    "    print(str(iter_counter))\n",
    "    cv2.imshow('img',img)\n",
    "    k = cv2.waitKey(30) & 0xff\n",
    "    if k == 27:\n",
    "        break\n",
    "\n",
    "time.sleep(10)\n",
    "\n",
    "while 1:\n",
    "    ret, img = cap.read()\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_cascade.detectMultiScale(gray, 1.3, 5)\n",
    "    \n",
    "    # add this\n",
    "    # image, reject levels level weights.\n",
    "    \"\"\"\"\"\n",
    "    Try diffrent Params in diff light / brightness / face size (if far or close)\n",
    "    \"\"\"\n",
    "    masks = mask_cascade.detectMultiScale(gray,1.3,19) \n",
    "    #FOR RAB:\n",
    "    #1.3, 15 WORK WELL\n",
    "    \n",
    "    #1.3 19 Seems best in tomer's conditions at night.\n",
    "    #1.3,11 DOESNT WORK FOR UNCOVER NOSE WELL BUT DECENT\n",
    "    #GAB 1.3 19 Seems decent (PROB NOT RAB)\n",
    "    \n",
    "    # GAB\n",
    "    # 1.6,30 224x224 (24x24)   # 1.3,20\n",
    "    \n",
    "    # add this\n",
    "    masked = True\n",
    "\n",
    "    for (x,y,w,h) in faces:\n",
    "        cv2.rectangle(img,(x,y),(x+w,y+h),(0,0,255),2)\n",
    "        masked = False\n",
    "\n",
    "\n",
    "        \n",
    "        roi_gray = gray[y:y+h, x:x+w]\n",
    "        roi_color = img[y:y+h, x:x+w]    \n",
    "    for (x,y,w,h) in masks:\n",
    "        masked = True\n",
    "        cv2.putText(img,'Mask',(x,y-10), cv2.FONT_HERSHEY_SIMPLEX, 1,(255, 255, 0),4)#((x*2+w)/2,(y*2+h)/2)\n",
    "        cv2.rectangle(img,(x,y),(x+w,y+h),(255,255,0),2)\n",
    "    # if haarcascade_frontalface_default.xml detects face but our didnt we put txt no mask\n",
    "    if not masked:\n",
    "        cv2.putText(img,'No mask',(x,y-10), cv2.FONT_HERSHEY_SIMPLEX, 1,(0, 0, 255),4)#((x*2+w)/2,(y*2+h)/2)\n",
    "    iter_counter += 1 \n",
    "    if not masked:\n",
    "        neg_counter += 1\n",
    "    if iter_counter == 200:\n",
    "        break\n",
    "    cv2.imshow('img',img)\n",
    "    k = cv2.waitKey(30) & 0xff\n",
    "    if k == 27:\n",
    "        break\n",
    "    print(str(iter_counter))\n",
    "\n",
    "score = (neg_counter+pos_counter)/iter_counter\n",
    "print(score)\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "clean-edgar",
   "metadata": {},
   "source": [
    "TEST ACC: 0.97"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hydraulic-blast",
   "metadata": {},
   "source": [
    "    WAYS TO IMPROVE:\n",
    "    train on more resized images (same images diff sizes to fit any camera at any distance) and with more angles to increase dataset \n",
    "    and add more random neg images, \n",
    "    try another boots method ( LB, etc),\n",
    "    try detecting edges with cv erode and canny and see if it increase our accuarcy,\n",
    "    try basic Haar train (the xml shows it as basic and also haar_cascade it so its not reliable to think its basic all applies \n",
    "    45 angles and more features so i might wanna use it on my dataset)\n",
    "    adjust the brightness of the picture according to day/night so the params of the cascade will work better on more situations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "expired-coast",
   "metadata": {},
   "source": [
    "Fifth ATTEMT TO CREATE haar cascade classifier for faceMask detection\n",
    "----------------------------------------------------------------------------------------------------------\n",
    "\n",
    "model name: RAB211Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "interpreted-yorkshire",
   "metadata": {},
   "source": [
    "    CHANGES:\n",
    "    files size increased to 224x224\n",
    "    the training is on 24 width 24 height to match original VJ\n",
    "    training methods changed:\n",
    "    mode: ALL\n",
    "    neg img: 1000\n",
    "    pos img: 2000\n",
    "    Boost type: RAB (Real Adaboost)\n",
    "    Max tree depth: 211 (like VJ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sixth-professor",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "face_cascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "\n",
    "#this is the cascade we just made. Call what you want\n",
    "mask_cascade = cv2.CascadeClassifier('haarcascade_facemask_RAB211Tree.xml')\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "isPrevMasked = True\n",
    "masked = True\n",
    "while 1:\n",
    "    ret, img = cap.read()\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_cascade.detectMultiScale(gray, 1.3, 5)\n",
    "    \n",
    "    \n",
    "    # add this\n",
    "    # image, reject levels level weights.\n",
    "    \"\"\"\"\"\n",
    "    Try diffrent Params in diff light / brightness / face size (if far or close)\n",
    "    \"\"\"\n",
    "    masks = mask_cascade.detectMultiScale(gray,1.34,18) #1.34,18/1.33,16 seems good at 20:00 yellow light\n",
    "    # 1.34,18\n",
    "    #FOR RAB:\n",
    "    #1.3, 15 WORK WELL\n",
    "    \n",
    "    #1.3 19 Seems best in tomer's conditions at night.\n",
    "    #1.3,11 DOESNT WORK FOR UNCOVER NOSE WELL BUT DECENT\n",
    "    #GAB 1.3 19 Seems decent (PROB NOT RAB)\n",
    "    \n",
    "    # GAB\n",
    "    # 1.6,30 224x224 (24x24)   # 1.3,20\n",
    "    \n",
    "    # add this\n",
    "    #masked = True\n",
    "    masked = True\n",
    "    for (x,y,w,h) in faces:\n",
    "        if not isPrevMasked:\n",
    "            cv2.rectangle(img,(x,y),(x+w,y+h),(0,0,255),2)\n",
    "        masked = False\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "        roi_gray = gray[y:y+h, x:x+w]\n",
    "        roi_color = img[y:y+h, x:x+w]    \n",
    "    for (x,y,w,h) in masks:\n",
    "        masked = True\n",
    "        cv2.putText(img,'Mask',(x,y-10), cv2.FONT_HERSHEY_SIMPLEX, 1,(255, 255, 0),4)#((x*2+w)/2,(y*2+h)/2)\n",
    "        cv2.rectangle(img,(x,y),(x+w,y+h),(255,255,0),2)\n",
    "    # if haarcascade_frontalface_default.xml detects face but our didnt we put txt no mask\n",
    "    if (not isPrevMasked) and (not masked):\n",
    "        cv2.putText(img,'No mask',(x,y-10), cv2.FONT_HERSHEY_SIMPLEX, 1,(0, 0, 255),4)#((x*2+w)/2,(y*2+h)/2)\n",
    "\n",
    "\n",
    "    cv2.imshow('img',img)\n",
    "    k = cv2.waitKey(30) & 0xff\n",
    "    if k == 27:\n",
    "        break\n",
    "    if masked:\n",
    "        isPrevMasked = True\n",
    "    else:\n",
    "        isPrevMasked = False\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "closing-folks",
   "metadata": {},
   "source": [
    "    evaluate the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "better-worth",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Counter\n",
    "import numpy as np\n",
    "import cv2\n",
    "import time\n",
    "\n",
    "face_cascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "\n",
    "#this is the cascade we just made. Call what you want\n",
    "mask_cascade = cv2.CascadeClassifier('haarcascade_facemask_RAB211Tree.xml')\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "pos_counter = 0\n",
    "iter_counter = 0\n",
    "neg_counter = 0\n",
    "\n",
    "while 1:\n",
    "    ret, img = cap.read()\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_cascade.detectMultiScale(gray, 1.3, 5)\n",
    "    \n",
    "    # add this\n",
    "    # image, reject levels level weights.\n",
    "    \"\"\"\"\"\n",
    "    Try diffrent Params in diff light / brightness / face size (if far or close)\n",
    "    \"\"\"\n",
    "    masks = mask_cascade.detectMultiScale(gray,1.34,18) \n",
    "    #FOR RAB:\n",
    "    #1.3, 15 WORK WELL\n",
    "    \n",
    "    #1.3 19 Seems best in tomer's conditions at night.\n",
    "    #1.3,11 DOESNT WORK FOR UNCOVER NOSE WELL BUT DECENT\n",
    "    #GAB 1.3 19 Seems decent (PROB NOT RAB)\n",
    "    \n",
    "    # GAB\n",
    "    # 1.6,30 224x224 (24x24)   # 1.3,20\n",
    "    \n",
    "    # add this\n",
    "    masked = True\n",
    "\n",
    "    for (x,y,w,h) in faces:\n",
    "        cv2.rectangle(img,(x,y),(x+w,y+h),(0,0,255),2)\n",
    "        masked = False\n",
    "\n",
    "\n",
    "        \n",
    "        roi_gray = gray[y:y+h, x:x+w]\n",
    "        roi_color = img[y:y+h, x:x+w]    \n",
    "    for (x,y,w,h) in masks:\n",
    "        masked = True\n",
    "        cv2.putText(img,'Mask',(x,y-10), cv2.FONT_HERSHEY_SIMPLEX, 1,(255, 255, 0),4)#((x*2+w)/2,(y*2+h)/2)\n",
    "        cv2.rectangle(img,(x,y),(x+w,y+h),(255,255,0),2)\n",
    "    # if haarcascade_frontalface_default.xml detects face but our didnt we put txt no mask\n",
    "    if not masked:\n",
    "        cv2.putText(img,'No mask',(x,y-10), cv2.FONT_HERSHEY_SIMPLEX, 1,(0, 0, 255),4)#((x*2+w)/2,(y*2+h)/2)\n",
    "    iter_counter += 1 \n",
    "    if masked:\n",
    "        pos_counter += 1\n",
    "    if iter_counter == 100:\n",
    "        break\n",
    "    print(str(iter_counter))\n",
    "    cv2.imshow('img',img)\n",
    "    k = cv2.waitKey(30) & 0xff\n",
    "    if k == 27:\n",
    "        break\n",
    "\n",
    "time.sleep(10)\n",
    "\n",
    "while 1:\n",
    "    ret, img = cap.read()\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_cascade.detectMultiScale(gray, 1.3, 5)\n",
    "    \n",
    "    # add this\n",
    "    # image, reject levels level weights.\n",
    "    \"\"\"\"\"\n",
    "    Try diffrent Params in diff light / brightness / face size (if far or close)\n",
    "    \"\"\"\n",
    "    masks = mask_cascade.detectMultiScale(gray,1.3,19) \n",
    "    #FOR RAB:\n",
    "    #1.3, 15 WORK WELL\n",
    "    \n",
    "    #1.3 19 Seems best in tomer's conditions at night.\n",
    "    #1.3,11 DOESNT WORK FOR UNCOVER NOSE WELL BUT DECENT\n",
    "    #GAB 1.3 19 Seems decent (PROB NOT RAB)\n",
    "    \n",
    "    # GAB\n",
    "    # 1.6,30 224x224 (24x24)   # 1.3,20\n",
    "    \n",
    "    # add this\n",
    "    masked = True\n",
    "\n",
    "    for (x,y,w,h) in faces:\n",
    "        cv2.rectangle(img,(x,y),(x+w,y+h),(0,0,255),2)\n",
    "        masked = False\n",
    "\n",
    "\n",
    "        \n",
    "        roi_gray = gray[y:y+h, x:x+w]\n",
    "        roi_color = img[y:y+h, x:x+w]    \n",
    "    for (x,y,w,h) in masks:\n",
    "        masked = True\n",
    "        cv2.putText(img,'Mask',(x,y-10), cv2.FONT_HERSHEY_SIMPLEX, 1,(255, 255, 0),4)#((x*2+w)/2,(y*2+h)/2)\n",
    "        cv2.rectangle(img,(x,y),(x+w,y+h),(255,255,0),2)\n",
    "    # if haarcascade_frontalface_default.xml detects face but our didnt we put txt no mask\n",
    "    if not masked:\n",
    "        cv2.putText(img,'No mask',(x,y-10), cv2.FONT_HERSHEY_SIMPLEX, 1,(0, 0, 255),4)#((x*2+w)/2,(y*2+h)/2)\n",
    "    iter_counter += 1 \n",
    "    if not masked:\n",
    "        neg_counter += 1\n",
    "    if iter_counter == 200:\n",
    "        break\n",
    "    cv2.imshow('img',img)\n",
    "    k = cv2.waitKey(30) & 0xff\n",
    "    if k == 27:\n",
    "        break\n",
    "    print(str(iter_counter))\n",
    "\n",
    "score = (neg_counter+pos_counter)/iter_counter\n",
    "print(score)\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sitting-fluid",
   "metadata": {},
   "source": [
    "TEST ACC: 0.99"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "greek-adult",
   "metadata": {},
   "source": [
    "    HOW TO IMPROVE:\n",
    "    train on more resized images (same images diff sizes to fit any camera at any distance) and with more angles to increase dataset \n",
    "    and add more random neg images, \n",
    "    try another boots method ( LB, etc),\n",
    "    try detecting edges with cv erode and canny and see if it increase our accuarcy,\n",
    "    try basic Haar train (the xml shows it as basic and also haar_cascade it so its not reliable to think its basic all applies \n",
    "    45 angles and more features so i might wanna use it on my dataset)\n",
    "    adjust the brightness of the picture according to day/night so the params of the cascade will work better on more situations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "listed-threshold",
   "metadata": {},
   "source": [
    "    i felt like trying other adaboost type and finish after this (12 days of work)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "democratic-intelligence",
   "metadata": {},
   "source": [
    "Sixth ATTEMT TO CREATE haar cascade classifier for faceMask detection\n",
    "----------------------------------------------------------------------------------------------------------\n",
    "\n",
    "model name: GAB211Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "streaming-mortality",
   "metadata": {},
   "source": [
    "    CHANGES:\n",
    "    V1\n",
    "    Max depth tree count changed to 211 to fit VJ\n",
    "    training methods changed:\n",
    "    mode: Basic (fit VJ according to haar_classifiers*.xml)\n",
    "    neg img: 1000\n",
    "    pos img: 2000\n",
    "    Boost type: GAB (Gentle Adaboost)\n",
    "    depth tree 211"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "liked-water",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "face_cascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "\n",
    "#this is the cascade we just made. Call what you want\n",
    "mask_cascade = cv2.CascadeClassifier('haarcascade_face_mask.xml')\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while 1:\n",
    "    ret, img = cap.read()\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_cascade.detectMultiScale(gray, 1.3, 5)\n",
    "    \n",
    "    # add this\n",
    "    # image, reject levels level weights.\n",
    "    \"\"\"\"\"\n",
    "    Try diffrent Params in diff light / brightness / face size (if far or close)\n",
    "    \"\"\"\n",
    "    masks = mask_cascade.detectMultiScale(gray,1.34,18) \n",
    "    #FOR RAB:\n",
    "    #1.3, 15 WORK WELL\n",
    "    \n",
    "    #1.3 19 Seems best in tomer's conditions at night.\n",
    "    #1.3,11 DOESNT WORK FOR UNCOVER NOSE WELL BUT DECENT\n",
    "    #GAB 1.3 19 Seems decent (PROB NOT RAB)\n",
    "    \n",
    "    # GAB\n",
    "    # 1.6,30 224x224 (24x24)   # 1.3,20\n",
    "    \n",
    "    # add this\n",
    "    masked = True\n",
    "\n",
    "    for (x,y,w,h) in faces:\n",
    "        cv2.rectangle(img,(x,y),(x+w,y+h),(0,0,255),2)\n",
    "        masked = False\n",
    "\n",
    "\n",
    "        \n",
    "        roi_gray = gray[y:y+h, x:x+w]\n",
    "        roi_color = img[y:y+h, x:x+w]    \n",
    "    for (x,y,w,h) in masks:\n",
    "        masked = True\n",
    "        cv2.putText(img,'Mask',(x,y-10), cv2.FONT_HERSHEY_SIMPLEX, 1,(255, 255, 0),4)#((x*2+w)/2,(y*2+h)/2)\n",
    "        cv2.rectangle(img,(x,y),(x+w,y+h),(255,255,0),2)\n",
    "    # if haarcascade_frontalface_default.xml detects face but our didnt we put txt no mask\n",
    "    if not masked:\n",
    "        cv2.putText(img,'No mask',(x,y-10), cv2.FONT_HERSHEY_SIMPLEX, 1,(0, 0, 255),4)#((x*2+w)/2,(y*2+h)/2)\n",
    "\n",
    "\n",
    "    cv2.imshow('img',img)\n",
    "    k = cv2.waitKey(30) & 0xff\n",
    "    if k == 27:\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "crazy-retreat",
   "metadata": {},
   "source": [
    "Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "strong-transportation",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Counter\n",
    "import numpy as np\n",
    "import cv2\n",
    "import time\n",
    "\n",
    "face_cascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "\n",
    "#this is the cascade we just made. Call what you want\n",
    "mask_cascade = cv2.CascadeClassifier('haarcascade_face_mask.xml')\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "pos_counter = 0\n",
    "iter_counter = 0\n",
    "neg_counter = 0\n",
    "\n",
    "while 1:\n",
    "    ret, img = cap.read()\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_cascade.detectMultiScale(gray, 1.3, 5)\n",
    "    \n",
    "    # add this\n",
    "    # image, reject levels level weights.\n",
    "    \"\"\"\"\"\n",
    "    Try diffrent Params in diff light / brightness / face size (if far or close)\n",
    "    \"\"\"\n",
    "    masks = mask_cascade.detectMultiScale(gray,1.34,18) \n",
    "    #FOR RAB:\n",
    "    #1.3, 15 WORK WELL\n",
    "    \n",
    "    #1.3 19 Seems best in tomer's conditions at night.\n",
    "    #1.3,11 DOESNT WORK FOR UNCOVER NOSE WELL BUT DECENT\n",
    "    #GAB 1.3 19 Seems decent (PROB NOT RAB)\n",
    "    \n",
    "    # GAB\n",
    "    # 1.6,30 224x224 (24x24)   # 1.3,20\n",
    "    \n",
    "    # add this\n",
    "    masked = True\n",
    "\n",
    "    for (x,y,w,h) in faces:\n",
    "        cv2.rectangle(img,(x,y),(x+w,y+h),(0,0,255),2)\n",
    "        masked = False\n",
    "\n",
    "\n",
    "        \n",
    "        roi_gray = gray[y:y+h, x:x+w]\n",
    "        roi_color = img[y:y+h, x:x+w]    \n",
    "    for (x,y,w,h) in masks:\n",
    "        masked = True\n",
    "        cv2.putText(img,'Mask',(x,y-10), cv2.FONT_HERSHEY_SIMPLEX, 1,(255, 255, 0),4)#((x*2+w)/2,(y*2+h)/2)\n",
    "        cv2.rectangle(img,(x,y),(x+w,y+h),(255,255,0),2)\n",
    "    # if haarcascade_frontalface_default.xml detects face but our didnt we put txt no mask\n",
    "    if not masked:\n",
    "        cv2.putText(img,'No mask',(x,y-10), cv2.FONT_HERSHEY_SIMPLEX, 1,(0, 0, 255),4)#((x*2+w)/2,(y*2+h)/2)\n",
    "    iter_counter += 1 \n",
    "    if masked:\n",
    "        pos_counter += 1\n",
    "    if iter_counter == 100:\n",
    "        break\n",
    "    print(str(iter_counter))\n",
    "    cv2.imshow('img',img)\n",
    "    k = cv2.waitKey(30) & 0xff\n",
    "    if k == 27:\n",
    "        break\n",
    "\n",
    "time.sleep(10)\n",
    "\n",
    "while 1:\n",
    "    ret, img = cap.read()\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_cascade.detectMultiScale(gray, 1.3, 5)\n",
    "    \n",
    "    # add this\n",
    "    # image, reject levels level weights.\n",
    "    \"\"\"\"\"\n",
    "    Try diffrent Params in diff light / brightness / face size (if far or close)\n",
    "    \"\"\"\n",
    "    masks = mask_cascade.detectMultiScale(gray,1.3,19) \n",
    "    #FOR RAB:\n",
    "    #1.3, 15 WORK WELL\n",
    "    \n",
    "    #1.3 19 Seems best in tomer's conditions at night.\n",
    "    #1.3,11 DOESNT WORK FOR UNCOVER NOSE WELL BUT DECENT\n",
    "    #GAB 1.3 19 Seems decent (PROB NOT RAB)\n",
    "    \n",
    "    # GAB\n",
    "    # 1.6,30 224x224 (24x24)   # 1.3,20\n",
    "    \n",
    "    # add this\n",
    "    masked = True\n",
    "\n",
    "    for (x,y,w,h) in faces:\n",
    "        cv2.rectangle(img,(x,y),(x+w,y+h),(0,0,255),2)\n",
    "        masked = False\n",
    "\n",
    "\n",
    "        \n",
    "        roi_gray = gray[y:y+h, x:x+w]\n",
    "        roi_color = img[y:y+h, x:x+w]    \n",
    "    for (x,y,w,h) in masks:\n",
    "        masked = True\n",
    "        cv2.putText(img,'Mask',(x,y-10), cv2.FONT_HERSHEY_SIMPLEX, 1,(255, 255, 0),4)#((x*2+w)/2,(y*2+h)/2)\n",
    "        cv2.rectangle(img,(x,y),(x+w,y+h),(255,255,0),2)\n",
    "    # if haarcascade_frontalface_default.xml detects face but our didnt we put txt no mask\n",
    "    if not masked:\n",
    "        cv2.putText(img,'No mask',(x,y-10), cv2.FONT_HERSHEY_SIMPLEX, 1,(0, 0, 255),4)#((x*2+w)/2,(y*2+h)/2)\n",
    "    iter_counter += 1 \n",
    "    if not masked:\n",
    "        neg_counter += 1\n",
    "    if iter_counter == 200:\n",
    "        break\n",
    "    cv2.imshow('img',img)\n",
    "    k = cv2.waitKey(30) & 0xff\n",
    "    if k == 27:\n",
    "        break\n",
    "    print(str(iter_counter))\n",
    "\n",
    "score = (neg_counter+pos_counter)/iter_counter\n",
    "print(score)\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "seeing-permission",
   "metadata": {},
   "source": [
    "TEST ACC: 0.965"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "alike-equilibrium",
   "metadata": {},
   "source": [
    "TEST ACC: 1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "worse-cycling",
   "metadata": {},
   "source": [
    "Avg ACC: 0.9825"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pregnant-disposal",
   "metadata": {},
   "source": [
    "we tested first got 0.965 then again on another 200 photos and got 1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "genuine-gathering",
   "metadata": {},
   "source": [
    "    HOW TO IMPROVE:\n",
    "    train on more resized images (same images diff sizes to fit any camera at any distance) and with more angles to increase dataset and add more random neg images, \n",
    "    try another boots method (LB, etc),\n",
    "    try detecting edges with cv erode and canny and see if it increase our accuarcy,\n",
    "    train on bigger samples - Req alot of RAM\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afraid-conviction",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
